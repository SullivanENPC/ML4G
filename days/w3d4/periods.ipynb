{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "devices = [\"cuda:0\", \"cuda:1\"]\n",
    "device = devices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# setting pad_token_id gets rid of a warning that shows up when calling .generate()\n",
    "ref_model = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_periods(sentences):\n",
    "    return [sentence.count('.') for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"My feedback for the Machine Learning Alignment Bootcamp is\"\n",
    "tokens = tokenizer(sentence)\n",
    "tokens = torch.tensor(tokens.input_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction = output.logits[0,-1].argmax(dim=-1)\n",
    "print(tokenizer.decode([prediction]))\n",
    "print(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My feedback for the Machine Learning Alignment Bootcamp is so much wonderful, we began to work together with the community to build a robust, and scalable, performance-enhancing machine learning solution. The Machine Learning Alignment Bootcamp is an excellent introduction to machine learning, and we are thrilled to be involved in bringing it to you.\n",
      "\n",
      "We are excited that we are able to deliver a truly comprehensive and comprehensive document on the tools and techniques that can help you explore the world of machine learning. This book will help you navigate through the world of machine learning to understand the basics of the world-\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(tokens, min_length=120, max_length=120, top_k=len(tokenizer), temperature=0.6, do_sample=True)\n",
    "print(tokenizer.decode(output.squeeze(0)))\n",
    "# docs for generate(): \n",
    "# https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "bert = transformers.AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "bert.to(device)\n",
    "bert.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_sentiment(strs):\n",
    "    tokens = bert_tokenizer(strs, padding=True)\n",
    "    tokens = torch.tensor(tokens.input_ids, dtype=torch.long, device=device)\n",
    "    with torch.no_grad():\n",
    "        output = bert(tokens)\n",
    "    return output.logits.softmax(dim=-1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-3e1cfd540ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_positive_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Grrr I am angry!!!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Life is great!\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-153-3e1cfd540ad2>\u001b[0m in \u001b[0;36mget_positive_sentiment\u001b[0;34m(strs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_positive_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GENERATED_TOKENS = 20 # num tokens generated in an episode\n",
    "BATCH_SIZE = 50 # num episodes in a batch\n",
    "LR = 3e-5\n",
    "VOCAB_SIZE = 50257\n",
    "\n",
    "PROMPT = \"This is\"\n",
    "PROMPT_TOKENS = torch.tensor(tokenizer(PROMPT).input_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
    "PROMPT_BATCH = PROMPT_TOKENS.repeat(BATCH_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/danielb/tom-dan/b1731d58d1dd4d7e97a16c0a4a348aa0\n",
      "\n",
      "<ipython-input-196-00d066f911f6>:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rewards_per_batch = torch.tensor(sentence_reward_fn(generated_text), dtype=torch.float32, device=device)\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/danielb/tom-dan/b1731d58d1dd4d7e97a16c0a4a348aa0\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     entropy [100]             : (3.8491384983062744, 4.783637523651123)\n",
      "COMET INFO:     grad norm [100]           : (6.400127410888672, 13.617693901062012)\n",
      "COMET INFO:     kl [100]                  : (0.2592507004737854, 0.5355492234230042)\n",
      "COMET INFO:     loss [110]                : (-0.48893728852272034, 0.29212549328804016)\n",
      "COMET INFO:     policy loss [100]         : (-0.5347968339920044, 0.25495100021362305)\n",
      "COMET INFO:     unnormalized reward [100] : (0.171010360121727, 0.9987603425979614)\n",
      "COMET INFO:     value head loss [100]     : (4.162466049194336, 8.061721801757812)\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (570 bytes)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "def train(\n",
    "        model, \n",
    "        ref_model, \n",
    "        value_head, \n",
    "        num_epochs, \n",
    "        tokenizer, \n",
    "        prompt_batch, \n",
    "        lr, \n",
    "        num_generated_tokens, \n",
    "        kl_coefficient,\n",
    "        entropy_coefficient,\n",
    "        value_head_coefficient,\n",
    "        # takes a list of sentences, returns score for each sentence\n",
    "        sentence_reward_fn = count_periods,\n",
    "        run_experiment = True,\n",
    "):\n",
    "    batch_size = prompt_batch.shape[0]\n",
    "    all_params = list(model.parameters()) + list(value_head.parameters())\n",
    "    optim = torch.optim.Adam(all_params, lr=lr)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lambda x: x / num_epochs)\n",
    "    model.train()\n",
    "    value_head.train()\n",
    "    ref_model.eval()\n",
    "    \n",
    "    if run_experiment:\n",
    "        experiment = Experiment(\n",
    "            api_key=\"72XQSdnwnBcob4Q8NpbJHewll\",\n",
    "            project_name=\"tom-dan\",\n",
    "            workspace=\"danielb\",\n",
    "        )\n",
    "    for time_step in range(num_epochs):\n",
    "        # Also possible to pass a single prompt with num_return_sequences=BATCH_SIZE\n",
    "        # generated = model.generate(tokens, do_sample=True, max_new_tokens=num_generated_tokens).logits[0,-1].argmax(dim=-1)\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(prompt_batch, do_sample=True, top_k=VOCAB_SIZE, max_new_tokens=num_generated_tokens)\n",
    "        # generated = model.generate(prompt_batch, do_sample=True, top_k=VOCAB_SIZE, max_new_tokens=num_generated_tokens, output_scores=True, return_dict_in_generate=True)\n",
    "        generated_text = tokenizer.batch_decode(generated)\n",
    "        rewards_per_batch = torch.tensor(sentence_reward_fn(generated_text), dtype=torch.float32, device=device)\n",
    "        # normalize the rewards\n",
    "        normalized_rewards_per_batch = (rewards_per_batch - rewards_per_batch.mean()) / (rewards_per_batch.std() + 1e-5)\n",
    "\n",
    "        # Pass all tokens to next forward pass \n",
    "        full_output = model(generated, output_hidden_states=True)     \n",
    "        \n",
    "        output = full_output.logits\n",
    "        output_softmax = torch.nn.functional.softmax(output, dim=-1)\n",
    "\n",
    "        # predicted_probs[i, j] = output_softmax[i, j, generated[i, j+1]]\n",
    "        #   = the output probability of the next token (for batch i, token j)\n",
    "        predicted_probs = torch.gather(output_softmax[:,:-1], dim=2, index=generated[:,1:].unsqueeze(-1)).squeeze(-1)\n",
    "        # cut off the prompt\n",
    "        predicted_probs = predicted_probs[:,-num_generated_tokens:]\n",
    "        log_probs = (predicted_probs + 1e-10).log()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ref_dist = torch.nn.functional.softmax(ref_model(generated).logits, dim=-1)\n",
    "\n",
    "        #log_probs:           batch_size x num_generated_tokens\n",
    "        #rewards_per_batch:   batch_size\n",
    "        reward_per_action = log_probs * normalized_rewards_per_batch.unsqueeze(-1)\n",
    "        policy_loss = -torch.mean(reward_per_action)\n",
    "        \n",
    "        log_ref_dist = (ref_dist + 1e-10).log()\n",
    "        log_output_softmax = (output_softmax + 1e-10).log()\n",
    "        kl = (ref_dist * log_ref_dist - ref_dist * log_output_softmax).sum(dim=-1).mean()\n",
    "        entropy = -(output_softmax * log_output_softmax).sum(dim=-1).mean()\n",
    "\n",
    "        value_estimate = value_head(full_output.hidden_states[-1]).squeeze(-1) # batch_size x seq_len\n",
    "        # value_diffs = TD-1 error; batch_size x seq_len\n",
    "        value_diffs = value_estimate.clone()\n",
    "        value_diffs[:,:-1] -= value_estimate[:,1:].detach()\n",
    "        value_diffs[:,-1] -= normalized_rewards_per_batch\n",
    "        value_diffs = value_diffs[:,-num_generated_tokens:]\n",
    "        value_loss = (value_diffs ** 2).mean()\n",
    "        \n",
    "        # value_diff_det = value_diffs.detach()\n",
    "        # advantages = (value_diffs_det - value_diffs_det.mean(dim=-1).unsqueeze(-1)) / (value_diffs_det.std(dim=-1).unsqueeze(-1) + 1e-5)\n",
    "        \n",
    "        loss = policy_loss + value_head_coefficient * value_loss + kl_coefficient * kl + entropy_coefficient * -entropy\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(all_params, max_norm=1.0, error_if_nonfinite=True)\n",
    "        optim.step()\n",
    "        #lr_scheduler.step(rewards_per_batch.mean())\n",
    "        lr_scheduler.step()\n",
    "      \n",
    "        if run_experiment:\n",
    "            experiment.log_metric(\"loss\", loss)\n",
    "            experiment.log_metric(\"policy loss\", policy_loss)\n",
    "            experiment.log_metric(\"value head loss\", value_loss)\n",
    "            experiment.log_metric(\"unnormalized reward\", rewards_per_batch.mean())\n",
    "            experiment.log_metric(\"entropy\", entropy)\n",
    "            experiment.log_metric(\"kl\", kl)\n",
    "            experiment.log_metric(\"grad norm\", grad_norm)\n",
    "    \n",
    "    if run_experiment:\n",
    "        # this is a JupyterLab notebook so we have to explicitly end the experiment\n",
    "        experiment.end()\n",
    "        \n",
    "reinitialize_model = True\n",
    "\n",
    "if reinitialize_model:\n",
    "    model = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "    # attaches to last hidden output of GPT2\n",
    "    value_head = torch.nn.Linear(768, 1).to(device)\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    value_head=value_head,\n",
    "    tokenizer=tokenizer, \n",
    "    num_epochs=100, \n",
    "    prompt_batch=PROMPT_BATCH, \n",
    "    lr=LR, \n",
    "    num_generated_tokens=NUM_GENERATED_TOKENS,\n",
    "    kl_coefficient=0.1,\n",
    "    entropy_coefficient=0,\n",
    "    value_head_coefficient=0,\n",
    "    run_experiment = True,\n",
    "    sentence_reward_fn=get_positive_sentiment,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
