{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%run w2d1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Dict, Optional, List, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch as t\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import einsum\n",
    "from einops import rearrange, reduce, repeat\n",
    "import bert_tests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "# print(tokenizer(\"hello what's up\"))\n",
    "# uncased_tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# print(uncased_tokenizer([\"hello what's up\"]))\n",
    "# coded = uncased_tokenizer([\"hello what's up\"])\n",
    "# uncased_tokenizer.batch_decode(coded['input_ids'])\n",
    "# tokenizer.batch_decode(coded['input_ids'])\n",
    "# uncased_tokenizer.batch_decode(coded['input_ids'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "my_bert, pretrained_bert = load_pretrained_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fish loves to eat [MASK].\n",
      "it fish them meat food eggs honey insects too rice everything water vegetables this fruit apples him there again here\n",
      "tensor([0.1738, 0.0980, 0.0947, 0.0410, 0.0336, 0.0251, 0.0134, 0.0130, 0.0126,\n",
      "        0.0119, 0.0092, 0.0090, 0.0088, 0.0083, 0.0072, 0.0069, 0.0063, 0.0060,\n",
      "        0.0058, 0.0054], grad_fn=<IndexBackward0>)\n",
      "\n",
      "The fish loves to eat [MASK]\n",
      ". ;!?..., : | and \" but - so ред because as [UNK]') with\n",
      "tensor([9.4125e-01, 4.6098e-02, 1.1822e-02, 4.5820e-04, 1.2235e-04, 5.4506e-05,\n",
      "        3.6213e-05, 1.6483e-05, 1.2279e-05, 9.2127e-06, 6.5461e-06, 4.6536e-06,\n",
      "        3.4753e-06, 3.3669e-06, 2.9931e-06, 2.4598e-06, 1.9791e-06, 1.7764e-06,\n",
      "        1.3952e-06, 1.0635e-06], grad_fn=<IndexBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def feed_bert(model: nn.Module, text: str, tokenizer, top_k: int = 10):\n",
    "    input_ids: List[int] = tokenizer(text)[\"input_ids\"]\n",
    "    mask_idxs = [idx for idx, token in enumerate(input_ids) if token == 103]\n",
    "\n",
    "    all_logits = model(t.tensor([input_ids], dtype=t.long))[0]\n",
    "\n",
    "    print(text)\n",
    "    for mask_idx in mask_idxs:\n",
    "        logits = all_logits[mask_idx]\n",
    "        probs = t.softmax(logits, dim=0)\n",
    "\n",
    "        top_logit_idxs = t.argsort(logits, descending=True)[:top_k]\n",
    "        top_logit_words = tokenizer.decode(top_logit_idxs)\n",
    "\n",
    "        print(top_logit_words)\n",
    "        print(probs[top_logit_idxs])\n",
    "        print()\n",
    "\n",
    "my_bert.eval()\n",
    "feed_bert(my_bert, \"The fish loves to eat [MASK].\", tokenizer, top_k=20)\n",
    "feed_bert(my_bert, \"The fish loves to eat [MASK]\", tokenizer, top_k=20)\n",
    "#feed_bert(my_bert, \"The vegetarian fish loves to eat [MASK].\", tokenizer, top_k=20)\n",
    "#feed_bert(my_bert, \"The meat-eating fish loves to eat [MASK].\", tokenizer, top_k=20)\n",
    "#feed_bert(my_bert, \"The tiny fish loves to eat [MASK].\", tokenizer, top_k=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert MATCH!!!!!!!!\n",
      " SHAPE (1, 4, 28996) MEAN: 0.003031 STD: 0.5765 VALS [-0.5742 -0.432 0.1186 -0.7165 -0.5261 0.4967 1.223 0.3165 -0.3247 -0.5716...]\n",
      "bert MATCH!!!!!!!!\n",
      " SHAPE (1, 2) MEAN: 0.09479 STD: 1.411 VALS [-0.903 1.093]\n"
     ]
    }
   ],
   "source": [
    "bert_tests.test_bert_classification(Bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_collate_fn(\n",
    "    max_seq_length: int,\n",
    "    tokenizer: transformers.AutoTokenizer,\n",
    "    device: str,\n",
    "):\n",
    "    def fn(raw_xs: List[Tuple[str, str]]) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        labels: Tuple[str, ...]\n",
    "        texts: Tuple[str, ...]\n",
    "        labels, texts = zip(*raw_xs)\n",
    "\n",
    "        xs = t.tensor(\n",
    "            tokenizer(\n",
    "                list(texts),\n",
    "                padding=\"longest\",\n",
    "                max_length=max_seq_length,\n",
    "                truncation=True,\n",
    "            )['input_ids'],\n",
    "            dtype=t.long,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        ys = t.tensor([int(l == \"pos\") for l in labels], dtype=t.long, device=device)\n",
    "\n",
    "        return xs, ys\n",
    "\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cabcbddaf7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMDB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36mnew_fn\u001b[0;34m(root, split, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_check_default_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchtext/datasets/imdb.py\u001b[0m in \u001b[0;36mIMDB\u001b[0;34m(root, split)\u001b[0m\n\u001b[1;32m     34\u001b[0m     dataset_tar = download_from_url(URL, root=root,\n\u001b[1;32m     35\u001b[0m                                     hash_value=MD5, hash_type='md5')\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mextracted_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_tar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_imdb_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_RawTextIterableDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_LINES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchtext/utils.py\u001b[0m in \u001b[0;36mextract_archive\u001b[0;34m(from_path, to_path, overwrite)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfile_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2432\u001b[0m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2434\u001b[0;31m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFHeaderError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_zeros\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mfromtarfile\u001b[0;34m(cls, tarfile)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \"\"\"\n\u001b[1;32m   1104\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mfrombuf\u001b[0;34m(cls, buf, encoding, errors)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinkname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m157\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m257\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m265\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m297\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m297\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m329\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevmajor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m329\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m337\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevminor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m337\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m345\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mnts\u001b[0;34m(s, encoding, errors)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_train, data_test = torchtext.datasets.IMDB(root='.data', split=('train', 'test'))\n",
    "data_train = list(data_train)\n",
    "data_test = list(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "device = \"cuda\"\n",
    "collate_fn = get_imdb_collate_fn(512, tokenizer, device)\n",
    "\n",
    "dl_train_small = DataLoader(\n",
    "    random.sample(data_train, k=16),\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    data_train,\n",
    "    batch_size=8,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    # num_workers=0,\n",
    "    # pin_memory=True,\n",
    ")\n",
    "\n",
    "dl_test_small = DataLoader(\n",
    "    random.sample(data_test, k=256),\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dl_test = DataLoader(\n",
    "    data_test,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.012,acc=0.9375: : 3125it [16:13,  3.21it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.34,acc=0.90234375: : 1245it [06:28,  3.20it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-90a0525f9e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune_bert_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_bert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_test_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-90a0525f9e4c>\u001b[0m in \u001b[0;36mfinetune_bert_epoch\u001b[0;34m(model, dl_train, dl_test)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'loss={loss.item():.2},acc={get_accuracy(model, dl_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_accuracy(model: nn.Module, dl: DataLoader) -> float:\n",
    "\n",
    "    num_correct: int = 0\n",
    "    num_total: int = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pbar = tqdm(dl, disable=True)\n",
    "    for x, y in pbar:\n",
    "        _, out = model(x)\n",
    "        preds = t.argmax(out, dim=-1)\n",
    "\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_total += len(y)\n",
    "        pbar.set_description(f'acc={num_correct / num_total:.2}')\n",
    "\n",
    "    return num_correct / num_total\n",
    "\n",
    "def finetune_bert_epoch(model: nn.Module, dl_train: DataLoader, dl_test: DataLoader) -> nn.Module:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)  # broken?\n",
    "    pbar = tqdm(enumerate(dl_train))\n",
    "    for i, (x, y) in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        _, out = model(x)\n",
    "        loss = F.cross_entropy(input=out, target=y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            pbar.set_description(f'loss={loss.item():.2},acc={get_accuracy(model, dl_test)}')\n",
    "            model.train()\n",
    "\n",
    "    return model\n",
    "\n",
    "my_bert, _ = load_pretrained_bert(num_classes=2)\n",
    "#for i, (name, p) in enumerate(my_bert.named_parameters()):\n",
    "#    print(name)\n",
    "#    p.cuda()\n",
    "\n",
    "my_bert.cuda()\n",
    "my_bert.train()\n",
    "\n",
    "# print(get_accuracy(my_bert, dl_test_small))\n",
    "import gc\n",
    "gc.collect()\n",
    "t.cuda.empty_cache()\n",
    "epochs = 100\n",
    "for i in range(epochs):\n",
    "    print(i)\n",
    "    model = finetune_bert_epoch(my_bert, dl_train=dl_train, dl_test=dl_test_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training from Scratch on Masked Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes before filtering: 36718, 4358\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "data_train, data_test = torchtext.datasets.WikiText2(root='.data', split=('train', 'test'))\n",
    "\n",
    "data_train = list(data_train)\n",
    "data_test = list(data_test)\n",
    "print(f\"Sizes before filtering: {len(data_train)}, {len(data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes after filtering: 17262, 2072\n"
     ]
    }
   ],
   "source": [
    "def wiki_include(text: str) -> bool:\n",
    "    tokens = text.split(\" \")\n",
    "    if len(tokens) < 5:\n",
    "        return False\n",
    "    if \"=\" in tokens:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "data_train = [x for x in data_train if wiki_include(x)]\n",
    "data_test = [x for x in data_test if wiki_include(x)]\n",
    "print(f\"Sizes after filtering: {len(data_train)}, {len(data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_collate_fn(\n",
    "    max_seq_length: int,\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase,\n",
    "    pred_frac: float,\n",
    "    mask_frac: float,\n",
    "    random_frac: float,\n",
    "    device: str,\n",
    "):\n",
    "    assert 0 <= pred_frac <= 1 and 0 <= mask_frac <= 1 and 0 <= random_frac <= 1\n",
    "    assert 0 <= mask_frac + random_frac <= 1\n",
    "\n",
    "    def fn(texts: List[str]) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        # TODO: Sample random substring of texts to have more data diversity?\n",
    "        xs = t.tensor(\n",
    "            tokenizer(\n",
    "                list(texts),\n",
    "                padding=\"longest\",\n",
    "                max_length=max_seq_length,\n",
    "                truncation=True,\n",
    "            )[\"input_ids\"],\n",
    "            dtype=t.long,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        pred_mask = (t.rand_like(xs, dtype=t.float) < pred_frac) & (\n",
    "            (xs != tokenizer.pad_token_id) & (xs != tokenizer.cls_token_id) &\n",
    "            (xs != tokenizer.eos_token_id) & (xs != tokenizer.sep_token_id)\n",
    "        )\n",
    "        ys = t.masked_select(xs, pred_mask)\n",
    "\n",
    "        r = t.rand_like(xs, dtype=t.float)\n",
    "        mask_mask = r < mask_frac\n",
    "        random_mask = (mask_frac <= r) & (r < mask_frac + random_frac)\n",
    "\n",
    "        xs[pred_mask & mask_mask] = tokenizer.mask_token_id\n",
    "\n",
    "        random_input_ids = t.randint(\n",
    "            low=0, high=len(tokenizer), size=xs.shape, dtype=t.long, device=device\n",
    "        )\n",
    "        xs[pred_mask & random_mask] = random_input_ids[pred_mask & random_mask]\n",
    "\n",
    "        return xs, pred_mask, ys\n",
    "\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "device = \"cuda\"\n",
    "collate_fn = get_wiki_collate_fn(\n",
    "    max_seq_length=8,\n",
    "    tokenizer=transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\"),\n",
    "    pred_frac=0.15,\n",
    "    mask_frac=1,\n",
    "    random_frac=0,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dl_train_small = DataLoader(\n",
    "    random.sample(data_train, k=2),\n",
    "    batch_size=4,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    data_train,\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dl_test_small = DataLoader(\n",
    "    random.sample(data_test, k=256),\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dl_test = DataLoader(\n",
    "    data_test,\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlm_accuracy(model: nn.Module, dl: DataLoader) -> float:\n",
    "    num_correct: int = 0\n",
    "    num_total: int = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pbar = tqdm(dl, disable=True)\n",
    "    for x, pred_mask, y in pbar:\n",
    "        if len(y) == 0:\n",
    "            continue\n",
    "        logits = model(x)\n",
    "        pred_logits_flat = t.masked_select(logits, pred_mask.unsqueeze(-1))\n",
    "        pred_logits = pred_logits_flat.reshape((-1, logits.shape[-1]))\n",
    "        preds = t.argmax(pred_logits, dim=-1)\n",
    "\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_total += len(y)\n",
    "        pbar.set_description(f'acc={num_correct / num_total:.2}')\n",
    "\n",
    "    if num_total == 0:\n",
    "        return 0.0\n",
    "    return num_correct / num_total\n",
    "\n",
    "def mlm_epoch(model: nn.Module, dl_train: DataLoader, dl_test: DataLoader, lr: float, opbar=None) -> nn.Module:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # broken?\n",
    "    pbar = tqdm(enumerate(dl_train), leave=False)\n",
    "    for i, (x, pred_mask, y) in pbar:\n",
    "        if len(y) == 0:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        pred_logits_flat = t.masked_select(logits, pred_mask.unsqueeze(-1))\n",
    "        pred_logits = pred_logits_flat.reshape((-1, logits.shape[-1]))\n",
    "        loss = F.cross_entropy(input=pred_logits, target=y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            pbar.set_description(f'loss={loss.item():.3f},acc={get_mlm_accuracy(model, dl_test):.3f}')\n",
    "            model.train()\n",
    "            if opbar is not None:\n",
    "                opbar.set_description(f'loss={loss.item():.3f},acc={get_mlm_accuracy(model, dl_test):.3f}')\n",
    "            # print(tokenizer.decode(y))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_bert = Bert(\n",
    "    vocab_size=28996,\n",
    "    hidden_size=256,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    dropout=0,\n",
    "    intermediate_size=1024,\n",
    "    num_heads=12,\n",
    "    num_layers=2,\n",
    ")\n",
    "tiny_bert.to(device)\n",
    "None\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny_bert.train()\n",
    "# epochs = 1000\n",
    "# pbar = tqdm(range(epochs))\n",
    "# for i in pbar:\n",
    "#     # print(i)\n",
    "#     mlm_epoch(tiny_bert, dl_train_small, dl_train_small, 1e-3, pbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] The cow likes [MASK] eat [MASK] [SEP]\n",
      "to grass\n",
      "0 81.80654907226562\n",
      "1 45.52915954589844\n",
      "2 15.281932830810547\n",
      "3 0.0645010769367218\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 0.0\n",
      "9 0.0\n",
      "10 0.0\n",
      "11 0.0\n",
      "12 0.0\n",
      "13 0.0\n",
      "14 0.0\n",
      "15 0.0\n",
      "16 0.0\n",
      "17 0.0\n",
      "18 0.0\n",
      "19 0.0\n",
      "20 0.0\n",
      "21 0.0\n",
      "22 0.0\n",
      "23 0.0\n",
      "24 0.0\n",
      "25 0.0\n",
      "26 0.0\n",
      "27 0.0\n",
      "28 0.0\n",
      "29 0.0\n",
      "30 0.0\n",
      "31 0.0\n",
      "32 0.0\n",
      "33 0.0\n",
      "34 0.0\n",
      "35 0.0\n",
      "36 0.0\n",
      "37 0.0\n",
      "38 0.0\n",
      "39 0.0\n",
      "40 0.0\n",
      "41 0.0\n",
      "42 0.0\n",
      "43 0.0\n",
      "44 0.0\n",
      "45 0.0\n",
      "46 0.0\n",
      "47 0.0\n",
      "48 0.0\n",
      "49 0.0\n",
      "50 0.0\n",
      "51 0.0\n",
      "52 0.0\n",
      "53 0.0\n",
      "54 0.0\n",
      "55 0.0\n",
      "56 0.0\n",
      "57 0.0\n",
      "58 0.0\n",
      "59 0.0\n",
      "60 0.0\n",
      "61 0.0\n",
      "62 0.0\n",
      "63 0.0\n",
      "64 0.0\n",
      "65 0.0\n",
      "66 0.0\n",
      "67 0.0\n",
      "68 0.0\n",
      "69 0.0\n",
      "70 0.0\n",
      "71 0.0\n",
      "72 0.0\n",
      "73 0.0\n",
      "74 0.0\n",
      "75 0.0\n",
      "76 0.0\n",
      "77 0.0\n",
      "78 0.0\n",
      "79 0.0\n",
      "80 0.0\n",
      "81 0.0\n",
      "82 0.0\n",
      "83 0.0\n",
      "84 0.0\n",
      "85 0.0\n",
      "86 0.0\n",
      "87 0.0\n",
      "88 0.0\n",
      "89 0.0\n",
      "90 0.0\n",
      "91 0.0\n",
      "92 0.0\n",
      "93 0.0\n",
      "94 0.0\n",
      "95 0.0\n",
      "96 0.0\n",
      "97 0.0\n",
      "98 0.0\n",
      "99 0.0\n"
     ]
    }
   ],
   "source": [
    "batch_x = t.tensor(\n",
    "    tokenizer([\"The cow likes to eat grass\"])[\"input_ids\"],\n",
    "    device=\"cuda\",\n",
    "    dtype=t.long,\n",
    ")\n",
    "\n",
    "pred_mask = t.tensor(\n",
    "    [[False, False, False, False, True, False, True, False]],\n",
    "    dtype=t.bool,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "batch_y = t.masked_select(\n",
    "    batch_x,\n",
    "    pred_mask,\n",
    ")\n",
    "batch_x[pred_mask] = tokenizer.mask_token_id\n",
    "print(tokenizer.decode(batch_x[0]))\n",
    "print(tokenizer.decode(batch_y))\n",
    "\n",
    "tiny_bert.train()\n",
    "optimizer = optim.Adam(tiny_bert.parameters(), lr=1e-4)  # broken?\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = tiny_bert(batch_x)\n",
    "    pred_logits_flat = t.masked_select(logits, pred_mask.unsqueeze(-1))\n",
    "    pred_logits = pred_logits_flat.reshape((-1, logits.shape[-1]))\n",
    "    loss = F.cross_entropy(input=pred_logits, target=batch_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        print(i, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD6CAYAAACiefy7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAASUUlEQVR4nO3db4xc51XH8e+ZP2snqddp/pnEjmpXmFAXAamsqAiEUCmS0zZNBZWIhUQFVq1IBApCQqngDa+qSog/FaGV1YS0qEoIoSpOZQhQivKCUOIUVOy4adzQYuffbpPWdlu53rUPL2bWWVxvamfm7tzM+X6kKJ67szPP1Y1+OT7Pc58bmYkkafp1Jj0ASdLqMPAlqQgDX5KKMPAlqQgDX5KKMPAlqQgDX5KK6E16AK/kqquuys2bN096GJL0mvH4449/IzOvPt/PVi3wI+I9wDuBWeDuzPzHH/Q7mzdvZv/+/U0PTZKmRkR8faWfjdTSiYh7ImIuIg6cc3xHRDwZEYcj4k6AzPxMZr4fuB345VG+V5J08Ubt4d8L7Fh+ICK6wF3AzcA2YGdEbFv2lj8Y/lyStIpGCvzMfAR46ZzDNwGHM/PpzDwF3A/cGgMfBv4+M784yvdKki5eE6t0NgJHlr0+Ojz2m8DbgfdGxO0r/XJE7I6I/RGxf35+voHhSVJNqzZpm5kfAT5yAe/bA+wB2L59u1t5StKYNFHhPwNcv+z1puExSdIENRH4jwFbI2JLRMwAtwF7L+YDIuKWiNhz7NixBoYnSTWNuizzPuBR4IaIOBoRuzJzEbgDeBg4BDyQmQcv5nMz86HM3L1+/fpXNa5P/NvX+OyXnn1VvytJ02qkHn5m7lzh+D5g3yifPYoH9h/histmeNePXzepIUhS67RyL51RWzrbrp3liWeP4+MbJellrQz8UVs6b75ulhe/c4q5E98b88gk6bWrlYE/qm3XDf5H8cSzxyc8Eklqj6kM/Ddduw6Ag8+6ykeSlrQy8Eft4a9b2+cNV17KE89Z4UvSklYG/qg9fBj08Q/a0pGks1oZ+OOw7dpZvv7idzlxcmHSQ5GkVpjawH/zcOL20HMnJjwSSWqHVgb+OLZW2HbdLABPOHErSUBLA38cPfxr1q3hqtfN2MeXpKFWBv44RARvutaJW0laMrWBD4M+/lNzJzi1eGbSQ5GkiZvywJ9l4XTy1JwTt5LUysAf1374L0/c2taRpFYG/jgmbQE2X3kZl8507eNLEi0N/HHpdoIf2bCOr7xgS0eSpjrwATZefgnPHz856WFI0sRNfeBfM7uGuePuiy9JUx/4G2bX8u3vLfLt7y1OeiiSNFGtDPxxrdIB2DC7BoA52zqSimtl4I9rlQ7AhnVrAXjBto6k4loZ+ON0zewg8OdOWOFLqm3qA3+ppfOCLR1JxU194L9uTY9LZ7q2dCSVN/WBHxFsmF1rhS+pvKkPfBjsje9afEnVlQj8DbNrecFJW0nFtTLwx7kOHwYTty8cP0lmjuXzJOm1qJWBP851+DCo8E8unOH4Se+2lVRXKwN/3JbW4jtxK6myEoH/Qwa+JNUI/JdvvnKljqS6SgT+Neus8CWpROBfMtNldm3PHTMllVYi8GG4Ft+WjqTCagW+N19JKqxM4PuoQ0nVlQn8DbNrmTtxkjNnvNtWUk2tDPxxb60AsGHdGhZOJ9/87qmxfaYkvZa0MvDHvbUCDCp8cC2+pLpaGfhNOLu9ghO3kooqE/hLd9u6Fl9SVWUC/+p1bq8gqbYygb+m1+WKy2Z43gpfUlFlAh+WHnVo4EuqqVbgz65l7oQtHUk1lQr8S/odTi6cnvQwJGkiSgV+r9th8bR32kqqqVTgz3Q7LJw5M+lhSNJElAr8Xies8CWVVSvwux0WDHxJRZUK/H43WDhtS0dSTaUCv9fpsGjgSyqqVOD3e8GC++FLKmrVAj8i3hgRd0fEg6v1nefqW+FLKmykwI+IeyJiLiIOnHN8R0Q8GRGHI+JOgMx8OjN3jfJ9o+p1gzMJp63yJRU0aoV/L7Bj+YGI6AJ3ATcD24CdEbFtxO8Zi353cLpO3EqqaKTAz8xHgJfOOXwTcHhY0Z8C7gduvdDPjIjdEbE/IvbPz8+PMrzv0+sEAItW+JIKaqKHvxE4suz1UWBjRFwZER8DboyID670y5m5JzO3Z+b2q6++eqwDW6rw7eNLqqi3Wl+UmS8Ct6/W951Pvzuo8L35SlJFTVT4zwDXL3u9aXjsgkXELRGx59ixY2MdWG+pwnc/HUkFNRH4jwFbI2JLRMwAtwF7L+YDMvOhzNy9fv36sQ5sqYe/sGiFL6meUZdl3gc8CtwQEUcjYldmLgJ3AA8Dh4AHMvPg6EMd3UxvuErHCl9SQSP18DNz5wrH9wH7RvnsJvQ6S5O2VviS6mnl1grN9fCXJm2t8CXV08rAb6qHv7RKx3X4kipqZeA3ZamlY4UvqaJWBn5TLR23VpBUWSsDv/GWjpO2kgpqZeA3xRuvJFVWK/A7bq0gqa5SgW8PX1JlrQz85iZt7eFLqquVgd/cpK0VvqS6Whn4Tel545WkwmoFfscHoEiqq1TgL/XwT9nDl1RQKwO/6TttrfAlVdTKwG/sASj28CUV1srAb0rfzdMkFVYq8DudoBOuw5dUU6nAh8F+Olb4kioqF/gz3Y576UgqqZWB39QqHRhM3LpbpqSKWhn4Ta3SgcHNV1b4kipqZeA3qd8N1+FLKqlc4Pe64aStpJLKBX6/22HBG68kFVQv8DsdWzqSSioX+L1ueOOVpJIKBr4tHUk1tTLwm1yH3+8EC4u2dCTV08rAb3Idfr/b8cYrSSW1MvCbNFiWaUtHUj3lAt8KX1JV5QK/13GVjqSaygV+v9vhlOvwJRVUMPCt8CXVVC7we13vtJVUU7nA73fDG68klVQu8HvupSOpqHqB7zp8SUW1MvCb3FphxoeYSyqqlYHf6CMOu8GiPXxJBbUy8JvU63Q4fSbJNPQl1VIu8PvdALCPL6mcgoE/OGX7+JKqKRf4vWHge7etpGrKBf7Zlo47Zkoqplzg9zpW+JJqqhf4ZydtrfAl1VIu8GectJVUVLnAX6rwvflKUjX1Ar9jhS+ppnKBv7RKx0lbSdWUC/yz6/BdlimpmHKBv1Thn1q0wpdUS2+1vigiLgP+AjgF/Gtmfmq1vnu5vhW+pKJGqvAj4p6ImIuIA+cc3xERT0bE4Yi4c3j4F4EHM/P9wLtH+d5R9Dr28CXVNGpL515gx/IDEdEF7gJuBrYBOyNiG7AJODJ82+kRv/dVc/M0SVWNFPiZ+Qjw0jmHbwIOZ+bTmXkKuB+4FTjKIPRH/t5RuA5fUlVNBO9GXq7kYRD0G4FPA78UER8FHlrplyNid0Tsj4j98/PzYx+cFb6kqlZt0jYzvwP82gW8bw+wB2D79u1jL8P7Z2+8ssKXVEsTFf4zwPXLXm8aHmuFsy0dK3xJxTQR+I8BWyNiS0TMALcBey/mAyLilojYc+zYsbEP7uxumfbwJRUz6rLM+4BHgRsi4mhE7MrMReAO4GHgEPBAZh68mM/NzIcyc/f69etHGd559c/uh2+FL6mWkXr4mblzheP7gH2jfHZT+j0nbSXV1MqtFRpt6XSWHoBiS0dSLa0M/EZbOj7EXFJRrQz8JnU7QYR76Uiqp1zgw2Di1paOpGpaGfhN9vBhsEWyk7aSqmll4DfZw4fBQ1BclimpmlYGftP63fDGK0nllAz8XscKX1I9rQz8pnv4vW64LFNSOa0M/KZ7+DPdDqes8CUV08rAb5oVvqSKagZ+p+ONV5LKKRn4g3X4VviSamll4Dc/aWuFL6meVgZ+05O2/W6wsGiFL6mWVgZ+0/rdDgtW+JKKKRn4vY6rdCTVUzPwux03T5NUTsnA73eDRffSkVRMKwO/+e2RrfAl1dPKwG98e+ROxx6+pHJaGfhN8wEokioqGfg9e/iSCqoZ+B17+JLqKRn4Mz0DX1I9JQPfG68kVVQz8LsdFs8kmYa+pDpaGfiNr8PvBIATt5JKaWXgN75bZm9w2vbxJVXSysBvWm9Y4fsQFEmVlAz8fndw2otW+JIKKRn4va49fEn1lAz8fscevqR6agZ+zx6+pHpKBn6vYw9fUj0lA7/ftcKXVE/JwD9b4fsgc0mF1Ax8K3xJBZUM/Jmuq3Qk1dPKwG96L53e2RuvrPAl1dHKwG/8mbZLLR17+JIKaWXgN63fscKXVE/JwD+7tYI9fEmFlAz8pc3TThn4kgopGvhLFb4tHUl1lAz8s6t0nLSVVEjJwO/7ABRJBZUM/J4PQJFUUMnAd/M0SRUVDfzh1gr28CUVUjLwlx5i7iodSZWUDPxuxxuvJNVTMvAjgn43WPAh5pIKKRn4MOjjLyxa4UuqY9UCPyLeGBF3R8SDq/Wdr6TXCRat8CUVckGBHxH3RMRcRBw45/iOiHgyIg5HxJ2v9BmZ+XRm7hplsOPU73Z8AIqkUnoX+L57gT8HPrl0ICK6wF3ALwBHgcciYi/QBT50zu//embOjTzaMep1w1U6kkq5oMDPzEciYvM5h28CDmfm0wARcT9wa2Z+CHjXWEfZgF6n4zp8SaWM0sPfCBxZ9vro8Nh5RcSVEfEx4MaI+OArvG93ROyPiP3z8/MjDO+VzfQ63mkrqZQLbemMLDNfBG6/gPftAfYAbN++vbFE7nXCdfiSShmlwn8GuH7Z603DY68Jva4VvqRaRgn8x4CtEbElImaA24C94xhURNwSEXuOHTs2jo87r3433A9fUikXuizzPuBR4IaIOBoRuzJzEbgDeBg4BDyQmQfHMajMfCgzd69fv34cH3deg5aOFb6kOi50lc7OFY7vA/aNdUSrpN/t+ExbSaW0cmuF1WnpdJy0lVRKKwN/VVo6XbdWkFRLKwN/NfQ6rtKRVEvZwO93XYcvqZZWBv5q9fDdPE1SJa0M/NXq4dvSkVRJKwN/NXQjyDTwJdVRNvAlqZpWBv5q9PAlqZpWBv5q9PAlqZpWBr4kafwMfEkqwsCXpCJaGfhO2krS+LUy8J20laTxa2XgS5LGL9p8t2lEzANff5W/fhXwjTEO57Wg4jlDzfOueM5Q87wv9pzfkJlXn+8HrQ78UUTE/szcPulxrKaK5ww1z7viOUPN8x7nOdvSkaQiDHxJKmKaA3/PpAcwARXPGWqed8VzhprnPbZzntoeviTp/5vmCl+StMzUBX5E7IiIJyPicETcOenxNCUiro+Iz0fEExFxMCI+MDx+RUT8U0Q8Nfz36yc91nGLiG5E/GdEfHb4ektEfGF4zf86ImYmPcZxi4jLI+LBiPhyRByKiJ+a9msdEb8z/G/7QETcFxFrp/FaR8Q9ETEXEQeWHTvvtY2BjwzP/0sR8ZaL+a6pCvyI6AJ3ATcD24CdEbFtsqNqzCLwu5m5DXgr8BvDc70T+FxmbgU+N3w9bT4AHFr2+sPAn2TmDwPfBHZNZFTN+jPgHzLzR4GfYHD+U3utI2Ij8FvA9sz8MaAL3MZ0Xut7gR3nHFvp2t4MbB3+sxv46MV80VQFPnATcDgzn87MU8D9wK0THlMjMvO5zPzi8M8nGATARgbn+4nh2z4BvGciA2xIRGwC3gl8fPg6gLcBDw7fMo3nvB74WeBugMw8lZnfYsqvNdADLomIHnAp8BxTeK0z8xHgpXMOr3RtbwU+mQP/DlweEdde6HdNW+BvBI4se310eGyqRcRm4EbgC8CGzHxu+KPngQ2TGldD/hT4PeDM8PWVwLcyc3H4ehqv+RZgHvjLYSvr4xFxGVN8rTPzGeCPgP9lEPTHgMeZ/mu9ZKVrO1LGTVvglxMRrwP+FvjtzDy+/Gc5WII1NcuwIuJdwFxmPj7psayyHvAW4KOZeSPwHc5p30zhtX49g2p2C3AdcBnf3/YoYZzXdtoC/xng+mWvNw2PTaWI6DMI+09l5qeHh19Y+ive8N9zkxpfA34aeHdEfI1Bu+5tDHrblw//2g/Tec2PAkcz8wvD1w8y+B/ANF/rtwP/k5nzmbkAfJrB9Z/2a71kpWs7UsZNW+A/BmwdzuTPMJjk2TvhMTVi2Lu+GziUmX+87Ed7gfcN//w+4O9We2xNycwPZuamzNzM4Nr+S2b+CvB54L3Dt03VOQNk5vPAkYi4YXjo54EnmOJrzaCV89aIuHT43/rSOU/1tV5mpWu7F/jV4WqdtwLHlrV+frDMnKp/gHcAXwG+Cvz+pMfT4Hn+DIO/5n0J+K/hP+9g0NP+HPAU8M/AFZMea0Pn/3PAZ4d/fiPwH8Bh4G+ANZMeXwPn+5PA/uH1/gzw+mm/1sAfAl8GDgB/BayZxmsN3MdgnmKBwd/mdq10bYFgsBLxq8B/M1jFdMHf5Z22klTEtLV0JEkrMPAlqQgDX5KKMPAlqQgDX5KKMPAlqQgDX5KKMPAlqYj/A+73UJq/lhHyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6]\n",
      "The cow likes [MASK] eat [MASK]\n",
      "to grass broad them Kara fatty stickingtablepolis Leipzig\n",
      "tensor([118.074684143,  74.696380615,  69.747146606,  62.994777679,\n",
      "         62.295448303,  61.308742523,  60.646953583,  59.622581482,\n",
      "         59.100559235,  57.633613586], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "\n",
      "grass to ha sticking openings viewed injured Leipzig sweating traditionally\n",
      "tensor([112.907119751,  82.508247375,  64.210861206,  60.710426331,\n",
      "         57.982177734,  57.629398346,  57.253246307,  55.806079865,\n",
      "         55.079479218,  54.625976562], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tiny_bert.eval()\n",
    "feed_bert(tiny_bert, \"The cow likes [MASK] eat [MASK]\", tokenizer, top_k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.hooks import RemovableHandle\n",
    "\n",
    "class HookHandler:\n",
    "    def __init__(self):\n",
    "        self.activations = {}\n",
    "        self.hook_handles: List[RemovableHandle] = []\n",
    "\n",
    "    def reset(self):\n",
    "        for h in self.hook_handles:\n",
    "            h.remove()\n",
    "\n",
    "        self.activations = {}\n",
    "        self.hook_handles = []\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback): \n",
    "        self.reset()\n",
    "        print(\"All hooks removed!\")\n",
    "\n",
    "    def add_save_activation_hook(\n",
    "        self,\n",
    "        mod: nn.Module,\n",
    "        key: str,\n",
    "    ):\n",
    "        def fn(model, input, output):\n",
    "            self.activations[key] = output.detach()\n",
    "\n",
    "        self.hook_handles.append(mod.register_forward_hook(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed False\n",
      "t0.mha False\n",
      "tensor([[[ 0.7536, -0.4107,  0.9130,  ..., -0.3842, -0.2859,  0.1704],\n",
      "         [ 0.7461, -0.2790,  0.8417,  ..., -0.4808, -0.2501,  0.1761],\n",
      "         [ 0.7771, -0.3439,  0.8944,  ..., -0.4111, -0.2806,  0.1313],\n",
      "         ...,\n",
      "         [ 0.7699, -0.3196,  1.0425,  ..., -0.3886, -0.1184,  0.0708],\n",
      "         [ 0.8119, -0.3057,  0.9970,  ..., -0.4310, -0.1342, -0.0458],\n",
      "         [ 0.7588, -0.3539,  0.9478,  ..., -0.3831, -0.2835,  0.1142]]],\n",
      "       device='cuda:0')\n",
      "t0 False\n",
      "final_mlp False\n",
      "logits False\n",
      "All hooks removed!\n"
     ]
    }
   ],
   "source": [
    "def acts_all_close(acts: t.Tensor, rtol: float = 1e-3):\n",
    "    return t.allclose(acts[0][0], acts[0][1], rtol=rtol)\n",
    "\n",
    "tiny_bert.eval()\n",
    "with HookHandler() as hh:\n",
    "    hh.add_save_activation_hook(tiny_bert.embedding, \"embed\")\n",
    "    hh.add_save_activation_hook(tiny_bert.transformer[0].mha, \"t0.mha\")\n",
    "    hh.add_save_activation_hook(tiny_bert.transformer[0], \"t0\")\n",
    "    hh.add_save_activation_hook(tiny_bert.lm_head.mlp, \"final_mlp\")\n",
    "\n",
    "    x = tokenizer([\"The cow likes [MASK] eat [MASK]\"])[\"input_ids\"]\n",
    "    logits = tiny_bert(t.tensor(x, dtype=t.long).cuda())\n",
    "\n",
    "    print(\"embed\", acts_all_close(hh.activations[\"embed\"]))\n",
    "    print(\"t0.mha\", acts_all_close(hh.activations[\"t0.mha\"], rtol=1e-3))\n",
    "    print(hh.activations[\"t0.mha\"])\n",
    "    print(\"t0\", acts_all_close(hh.activations[\"t0\"], rtol=1e-3))\n",
    "    print(\"final_mlp\", acts_all_close(hh.activations[\"final_mlp\"]))\n",
    "    print(\"logits\", acts_all_close(logits))  # The same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_bert(model: nn.Module, text: str, tokenizer, top_k: int = 10):\n",
    "    input_ids: List[int] = tokenizer(text)[\"input_ids\"]\n",
    "    mask_idxs = [idx for idx, token in enumerate(input_ids) if token == tokenizer.mask_token_id]\n",
    "    print(mask_idxs)\n",
    "\n",
    "    all_logits = model(t.tensor([input_ids], dtype=t.long))[0]\n",
    "\n",
    "    print(text)\n",
    "    for mask_idx in mask_idxs:\n",
    "        logits = all_logits[mask_idx]\n",
    "        probs = t.softmax(logits, dim=0)\n",
    "\n",
    "        top_logit_idxs = t.argsort(logits, descending=True)[:top_k]\n",
    "        top_logit_words = tokenizer.decode(top_logit_idxs)\n",
    "\n",
    "        t.set_printoptions(precision=9)\n",
    "        print(top_logit_words)\n",
    "        print(logits[top_logit_idxs])\n",
    "        print()\n",
    "        t.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] At the base of [MASK] of [SEP]', '[CLS] Languages which [MASK] not commonly [MASK] [SEP]']\n",
      "each may use\n",
      "*****************************\n",
      "-----------------------\n",
      "[6]\n",
      "[CLS] At the base of [MASK] of [SEP]\n",
      "of base ferry publishes At\n",
      "tensor([106.016815186,  60.250469208,  59.121616364,  57.998916626,\n",
      "         57.417720795], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "\n",
      "---------------------------------------\n",
      "[4, 7]\n",
      "[CLS] Languages which [MASK] not commonly [MASK] [SEP]\n",
      "not of Rey uselev\n",
      "tensor([95.449081421, 88.146469116, 68.647972107, 66.169685364, 63.083419800],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "\n",
      "use IF fibers storyline Emily\n",
      "tensor([93.822265625, 65.338890076, 62.282360077, 62.149761200, 61.994091034],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tiny_bert.eval()\n",
    "for (x, mask, y) in dl_train_small:\n",
    "    print(tokenizer.batch_decode(x))\n",
    "    print(tokenizer.decode(y))\n",
    "    print(\"*****************************\")\n",
    "    logits = tiny_bert(x)\n",
    "    #print(logits.shape)\n",
    "    # print(t.sort(logits, dim=-1).values[:, :3, -10:])\n",
    "    print(\"-----------------------\")\n",
    "    for xx in x:\n",
    "        feed_bert(tiny_bert, tokenizer.decode(xx), tokenizer, top_k=5)\n",
    "        print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bert, _ = load_pretrained_bert(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_bert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ef1a596c7b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl_train_small\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*****************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_bert' is not defined"
     ]
    }
   ],
   "source": [
    "test_bert.eval()\n",
    "for (x, mask, y) in dl_train_small:\n",
    "    print(tokenizer.batch_decode(x))\n",
    "    print(tokenizer.decode(y))\n",
    "    print(\"*****************************\")\n",
    "    logits, _ = test_bert(x)\n",
    "    #print(logits.shape)\n",
    "    # print(t.sort(logits, dim=-1).values[:, :3, -10:])\n",
    "    print(\"-----------------------\")\n",
    "    for xx in x:\n",
    "        feed_bert(lambda x : test_bert(x)[0], tokenizer.decode(xx), tokenizer, top_k=5)\n",
    "        print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0390,  0.1328, -0.0412,  ...,  0.1419,  0.0393,  0.0362],\n",
       "        [-0.0796,  0.1322, -0.1050,  ...,  0.1515,  0.0561,  0.0403],\n",
       "        [-0.0453,  0.0650, -0.0387,  ...,  0.0973,  0.1245,  0.0768],\n",
       "        ...,\n",
       "        [-0.1224,  0.1273, -0.0526,  ...,  0.1105,  0.0831,  0.0459],\n",
       "        [-0.0134,  0.0756, -0.1486,  ...,  0.1267,  0.0428,  0.1165],\n",
       "        [-0.0816,  0.1368, -0.0750,  ...,  0.0707,  0.1486,  0.1435]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_bert.lm_head.unembedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0315, -0.0883, -0.0943,  ..., -0.0812, -0.0664, -0.1027],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_bert.lm_head.unembedding.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
