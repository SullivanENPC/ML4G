{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/mlab/days/w3d3/rl_env/lib/python3.8/site-packages\")\n",
    "sys.path.append(\"/home/ubuntu/mlab/days/w3d3/rl_env/lib/python3.9/site-packages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn, optim\n",
    "import rl_tests\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from IPython.display import Video\n",
    "#from video_recorder import VideoRecorder\n",
    "import video_recorder\n",
    "import time\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [\"cuda:4\", \"cuda:5\", \"cuda:6\", \"cuda:7\"]\n",
    "DEVICE = DEVICES[0] if t.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_q_net MATCH!!!!!!!!\n",
      " SHAPE (16, 30) MEAN: -0.0177 STD: 0.09063 VALS [-0.1041 0.05202 0.00405 -0.08737 0.08234 -0.1316 -0.004065 -0.1105 0.02289 -0.1047...]\n"
     ]
    }
   ],
   "source": [
    "class Qnetwork(nn.Module):\n",
    "    def __init__(self, in_size : int, hidden_size : int, out_size : int):\n",
    "        super().__init__()#i presume in_size=obs_state; out_size=num_actions\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,out_size))\n",
    "    def forward(self, obs): #Tensor[..., obs_shape] -> Tensor[..., num_actions]\n",
    "        return self.model(obs)\n",
    "\n",
    "rl_tests.test_q_net(Qnetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_choice(env, eps:float,net:nn.Module,obs,device=\"cpu\"):\n",
    "    if t.rand(1)<eps:\n",
    "        choice = env.action_space.sample()\n",
    "        #print(\"random choice:\", choice)\n",
    "    else:\n",
    "        choice=t.argmax(net(obs),dim=-1).item()\n",
    "        #print(\"model choice:\", choice)\n",
    "\n",
    "    return choice\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,env,eps=0.05,device=\"cpu\"):\n",
    "    model.eval()\n",
    "    obs= env.reset()\n",
    "    tot_reward=0\n",
    "    done=False\n",
    "    with t.no_grad():\n",
    "        while not done:\n",
    "            obs,reward,done,_=env.step(make_choice(env,eps,model.to(device),t.tensor(obs,dtype=t.float).to(device),device))\n",
    "            tot_reward+=reward\n",
    "    return tot_reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Qnetwork(env.observation_space.shape[0],64, env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model,env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_training_loop(env, model,eps=(lambda t: 0.05),gamma=0.98,train_freq=16,batch_size=128,max_buffer_size=10000,adam_lr=1e-3,n_steps=20000,device=\"cpu\"):\n",
    "    buffer=collections.deque([],max_buffer_size)\n",
    "    optimizer=optim.Adam(model.parameters(),adam_lr)\n",
    "    lossfn = nn.MSELoss()\n",
    "    done=True\n",
    "    for i in range(batch_size):\n",
    "        if done == True:\n",
    "            obs=env.reset()\n",
    "        action= env.action_space.sample()\n",
    "        next_obs,reward,done,_=env.step(action)\n",
    "        buffer.append((obs,action,reward,done,next_obs))\n",
    "        obs=next_obs\n",
    "    done=True\n",
    "    returns = []\n",
    "    current_return = None\n",
    "    for i in range(n_steps):\n",
    "        if done == True:\n",
    "            if current_return is not None:\n",
    "                returns.append(current_return)\n",
    "            current_return = 0\n",
    "            ob=env.reset()\n",
    "        with t.no_grad():\n",
    "            action =make_choice(env,eps(i/n_steps),model.to(device),t.tensor(ob,dtype=t.float).to(device),device)\n",
    "            next_ob,reward,done,_=env.step(action)\n",
    "            current_return += reward\n",
    "            buffer.append((ob,action,reward,done,next_ob))\n",
    "            ob=next_ob\n",
    "        if i%train_freq==train_freq-1:\n",
    "            to_train = random.sample(list(buffer),batch_size)\n",
    "            obs, actions, rewards, dones, next_obs= zip(*to_train)\n",
    "            obs = t.tensor(np.array(obs), dtype=t.float).to(device)\n",
    "            actions = t.tensor(actions).to(device)\n",
    "            rewards = t.tensor(rewards).to(device)\n",
    "            dones = t.tensor(dones, dtype=t.float).to(device)\n",
    "            next_obs = t.tensor(np.array(next_obs), dtype=t.float).to(device)\n",
    "            with t.no_grad():\n",
    "                target=rewards + (1-dones)*t.max(model(next_obs),axis = -1).values\n",
    "            inpt = t.gather(model(obs),dim=-1,index=actions.unsqueeze(1)).squeeze(1)\n",
    "            loss = lossfn(inpt,target)\n",
    "            #if i%1000==999:\n",
    "                #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if i%1000==0:\n",
    "            #print('current reward', len(buffer)/(sum(item[3] for item in buffer)))\n",
    "            print('current return:', sum(returns[-10:])/max(1,len(returns[-10:])))\n",
    "        \n",
    "            \n",
    "                                                                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training_loop(env,model,n_steps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([420., 500., 500., 466., 489., 500., 447., 263., 500., 500., 427., 440.,\n",
       "        247., 262., 302., 425., 487., 380., 420., 432., 385., 430., 500., 437.,\n",
       "        378., 450., 500., 500., 446., 500., 432., 500., 495., 365., 500., 448.,\n",
       "        434., 364., 420., 247., 500., 442., 490., 500., 500., 461., 467., 408.,\n",
       "        500., 500., 417., 500., 500., 500., 438., 237., 334., 500., 500., 415.,\n",
       "        248., 336., 487., 500., 421., 500., 278., 500., 500., 500., 365., 412.,\n",
       "        361., 438., 500., 500., 498., 378., 497., 396., 500., 465., 500., 442.,\n",
       "        480., 393., 267., 241., 380., 500., 500., 453., 442., 473., 422., 500.,\n",
       "        500., 500., 437., 500.])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tensor([evaluate(model,env,eps=0) for i in range(0,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video(env,model,video_name,record=True,device=\"cpu\"):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    def show_state(env, step=0, info=\"\"):\n",
    "        plt.figure(3)\n",
    "        plt.clf()\n",
    "        plt.imshow(env.render(mode='rgb_array'))\n",
    "        plt.axis('off')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "    if record:\n",
    "        recorder = video_recorder.VideoRecorder(\n",
    "            env, f\"videos/{video_name}.mp4\")\n",
    "\n",
    "    states = 0\n",
    "    while not done:\n",
    "        states += 1\n",
    "        if record:\n",
    "            recorder.capture_frame()\n",
    "        else:  \n",
    "            show_state(env)\n",
    "        state, reward, done, _ = env.step(make_choice(env,0,model.to(device),t.tensor(state,dtype=t.float).to(device),device)) # Take a random action\n",
    "        #print(state)\n",
    "        total_reward += reward\n",
    "\n",
    "    print(f\"total reward: {total_reward}\")\n",
    "    if record:\n",
    "        recorder.close()\n",
    "    return Video(f\"videos/{video_name}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "generate_video(env,model,\"model_test_tentpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/model_test_tentpole.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Video(\"videos/model_test_tentpole.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Acrobot-v1\"\n",
    "env2 = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current return: 0.0\n",
      "current return: -500.0\n",
      "current return: -500.0\n",
      "current return: -500.0\n",
      "current return: -500.0\n",
      "current return: -500.0\n",
      "current return: -386.1\n",
      "current return: -88.2\n",
      "current return: -89.8\n",
      "current return: -97.3\n",
      "current return: -99.9\n",
      "current return: -119.3\n",
      "current return: -124.2\n",
      "current return: -94.2\n",
      "current return: -107.9\n",
      "current return: -115.6\n",
      "current return: -116.7\n",
      "current return: -100.0\n",
      "current return: -113.4\n",
      "current return: -103.7\n",
      "current return: -102.1\n",
      "current return: -115.7\n",
      "current return: -128.6\n",
      "current return: -122.0\n",
      "current return: -98.7\n",
      "current return: -105.9\n",
      "current return: -110.1\n",
      "current return: -115.7\n",
      "current return: -114.2\n",
      "current return: -135.4\n",
      "current return: -114.6\n",
      "current return: -107.9\n",
      "current return: -109.4\n",
      "current return: -115.1\n",
      "current return: -102.9\n",
      "current return: -108.9\n",
      "current return: -122.0\n",
      "current return: -118.9\n",
      "current return: -117.6\n",
      "current return: -118.5\n",
      "current return: -120.4\n",
      "current return: -112.9\n",
      "current return: -115.5\n",
      "current return: -120.8\n",
      "current return: -115.9\n",
      "current return: -118.0\n",
      "current return: -119.3\n",
      "current return: -108.1\n",
      "current return: -136.9\n",
      "current return: -119.1\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(53.5121, grad_fn=<MseLossBackward0>)\n",
      "current return: -424.6\n",
      "tensor(65.2543, grad_fn=<MseLossBackward0>)\n",
      "current return: -204.0\n",
      "tensor(39.6181, grad_fn=<MseLossBackward0>)\n",
      "current return: -164.9\n",
      "tensor(25.8927, grad_fn=<MseLossBackward0>)\n",
      "current return: -160.9\n",
      "tensor(23.2544, grad_fn=<MseLossBackward0>)\n",
      "current return: -198.5\n",
      "tensor(53.1056, grad_fn=<MseLossBackward0>)\n",
      "current return: -201.8\n",
      "tensor(26.4453, grad_fn=<MseLossBackward0>)\n",
      "current return: -192.4\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(53.5121, grad_fn=<MseLossBackward0>)\n",
      "current return: -424.6\n",
      "tensor(65.2543, grad_fn=<MseLossBackward0>)\n",
      "current return: -204.0\n",
      "tensor(39.6181, grad_fn=<MseLossBackward0>)\n",
      "current return: -164.9\n",
      "tensor(25.8927, grad_fn=<MseLossBackward0>)\n",
      "current return: -160.9\n",
      "tensor(23.2544, grad_fn=<MseLossBackward0>)\n",
      "current return: -198.5\n",
      "tensor(53.1056, grad_fn=<MseLossBackward0>)\n",
      "current return: -201.8\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(53.5121, grad_fn=<MseLossBackward0>)\n",
      "current return: -424.6\n",
      "tensor(65.2543, grad_fn=<MseLossBackward0>)\n",
      "current return: -204.0\n",
      "tensor(39.6181, grad_fn=<MseLossBackward0>)\n",
      "current return: -164.9\n",
      "tensor(25.8927, grad_fn=<MseLossBackward0>)\n",
      "current return: -160.9\n",
      "tensor(23.2544, grad_fn=<MseLossBackward0>)\n",
      "current return: -198.5\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(53.5121, grad_fn=<MseLossBackward0>)\n",
      "current return: -424.6\n",
      "tensor(65.2543, grad_fn=<MseLossBackward0>)\n",
      "current return: -204.0\n",
      "tensor(39.6181, grad_fn=<MseLossBackward0>)\n",
      "current return: -164.9\n",
      "tensor(25.8927, grad_fn=<MseLossBackward0>)\n",
      "current return: -160.9\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(53.5121, grad_fn=<MseLossBackward0>)\n",
      "current return: -424.6\n",
      "tensor(65.2543, grad_fn=<MseLossBackward0>)\n",
      "current return: -204.0\n",
      "tensor(39.6181, grad_fn=<MseLossBackward0>)\n",
      "current return: -164.9\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(53.5121, grad_fn=<MseLossBackward0>)\n",
      "current return: -424.6\n",
      "tensor(65.2543, grad_fn=<MseLossBackward0>)\n",
      "current return: -204.0\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(53.5121, grad_fn=<MseLossBackward0>)\n",
      "current return: -424.6\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(26.5378, grad_fn=<MseLossBackward0>)\n",
      "current return: -492.5\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(24.4884, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(10.9691, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(8.6496, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(20.0927, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(6.4416, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.9551, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n",
      "tensor(1.0397, grad_fn=<MseLossBackward0>)\n",
      "current return: -500.0\n"
     ]
    }
   ],
   "source": [
    "acrobot = Qnetwork(env2.observation_space.shape[0],64, env2.action_space.n)\n",
    "run_training_loop(env2, acrobot, eps=(lambda t: max(1-t*9,0.1)),gamma=0.99,train_freq=4,batch_size=128,max_buffer_size=10000,adam_lr=1e-4,n_steps=50000,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward: -110.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"videos/model_test_acrobot.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_video(env2,acrobot,\"model_test_acrobot\")\n",
    "Video(\"videos/model_test_acrobot.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_q_net MATCH!!!!!!!!\n",
      " SHAPE (16, 18) MEAN: -0.005567 STD: 0.1015 VALS [-0.1383 -0.04243 0.05936 -0.2105 0.05156 0.1246 -0.06088 -0.1034 0.09819 0.01536...]\n"
     ]
    }
   ],
   "source": [
    "class QnetworkBreakout(nn.Module):\n",
    "    def __init__(self, obs_n_channels : int, n_action_space : int):\n",
    "        super().__init__()#i presume in_size=obs_state; out_size=num_actions\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(obs_n_channels,32,8,stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,4,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, n_action_space),\n",
    "          )\n",
    "\n",
    "    def forward(self, obs): #Tensor[..., obs_shape] -> Tensor[..., num_actions]\n",
    "        return self.model(obs)\n",
    "\n",
    "#rl_tests.test_q_net(Qnetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current return: 0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (160 x 3). Kernel size: (8 x 8). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3ce03f7f93dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbreakout_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQnetworkBreakout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreakout_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_buffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madam_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-04bac7c1f101>\u001b[0m in \u001b[0;36mrun_training_loop\u001b[0;34m(env, model, eps, gamma, train_freq, batch_size, max_buffer_size, adam_lr, n_steps, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mnext_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0minpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-eda34b8b26bd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Tensor[..., obs_shape] -> Tensor[..., num_actions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mrl_tests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_q_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (160 x 3). Kernel size: (8 x 8). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "env_name = \"BreakoutNoFrameskip-v0\"\n",
    "env3 = gym.make(env_name)\n",
    "env3 = \n",
    "breakout_model = QnetworkBreakout(env3.observation_space.shape[0], env3.action_space.n)\n",
    "run_training_loop(env3, breakout_model, eps=(lambda t: 1-t*(1-0.01)),gamma=0.99,train_freq=4,batch_size=32,max_buffer_size=int(1e5),adam_lr=3e-5,n_steps=int(1e6),device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
