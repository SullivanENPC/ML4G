{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention pattern raw MATCH!!!!!!!!\n",
      " SHAPE (2, 12, 3, 3) MEAN: 0.004686 STD: 0.1078 VALS [0.0596 -0.04372 -0.1686 0.1675 -0.05231 0.06658 0.2362 0.162 0.07567 -0.15...]\n",
      "attention MATCH!!!!!!!!\n",
      " SHAPE (2, 3, 768) MEAN: -0.001142 STD: 0.1204 VALS [-0.1816 -0.05433 -0.2183 -0.009458 0.002117 -0.04871 -0.2099 -0.01656 -0.1198 0.1005...]\n",
      "bert MATCH!!!!!!!!\n",
      " SHAPE (2, 3, 768) MEAN: -0.001554 STD: 0.1736 VALS [-0.08316 -0.09165 -0.03188 -0.03013 0.1001 0.09549 -0.1046 0.07742 0.0424 0.05553...]\n",
      "bert mlp MATCH!!!!!!!!\n",
      " SHAPE (2, 3, 768) MEAN: -0.0001934 STD: 0.1044 VALS [-0.1153 0.1189 -0.0813 0.1021 0.0296 0.06182 0.0341 0.1446 0.2622 -0.08507...]\n",
      "layer norm MATCH!!!!!!!!\n",
      " SHAPE (20, 10) MEAN: -1.431e-08 STD: 1.003 VALS [0.6906 -0.84 1.881 1.711 -0.5116 -0.9577 -0.1387 -0.6943 -0.6741 -0.4662...]\n",
      "bert MATCH!!!!!!!!\n",
      " SHAPE (2, 3, 768) MEAN: -5.381e-09 STD: 1 VALS [0.007132 -0.04372 0.6502 -0.5972 -1.097 0.7267 0.1275 -0.6035 -0.2226 0.2145...]\n",
      "{'input_ids': [[101, 8667, 117, 146, 1821, 170, 5650, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "embedding MATCH!!!!!!!!\n",
      " SHAPE (2, 3, 5) MEAN: -0.06748 STD: 1.062 VALS [1.176 -0.1914 0.8212 1.047 -0.481 0.7106 -1.304 -1.307 -0.438 -0.2764...]\n",
      "True\n",
      "False\n",
      "bert embedding MATCH!!!!!!!!\n",
      " SHAPE (2, 3, 768) MEAN: 0 STD: 1 VALS [0.2316 0.08455 -0.5146 1.436 2.029 -1.117 2.775 -0.5305 -0.4485 -0.2485...]\n",
      "bert MATCH!!!!!!!!\n",
      " SHAPE (1, 4, 28996) MEAN: 0.003031 STD: 0.5765 VALS [-0.5742 -0.432 0.1186 -0.7165 -0.5261 0.4967 1.223 0.3165 -0.3247 -0.5716...]\n",
      "bert MATCH!!!!!!!!\n",
      " SHAPE (1, 2) MEAN: 0.09479 STD: 1.411 VALS [-0.903 1.093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "%run bert.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from tqdm.notebook import tqdm\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bert():\n",
    "    my_bert = Bert(\n",
    "        vocab_size=28996, hidden_size=384, max_position_embeddings=512, \n",
    "        type_vocab_size=2, dropout=0.1, intermediate_size=1536, \n",
    "        num_heads=6, num_layers=2, num_classes=2\n",
    "    )\n",
    "    return my_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "data_train, data_valid, data_test = torchtext.datasets.WikiText2(root='.data', split=('train', 'valid', 'test'))\n",
    "\n",
    "data_train_list = list(data_train)\n",
    "\n",
    "train_dataloader = DataLoader(data_train_list, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(data_test, batch_size=16)\n",
    "valid_dataloader = DataLoader(data_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = make_bert().cuda()\n",
    "lossfn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(bert.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bc26866ebc41ec8bba4c586698eeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.9441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6227, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552de340427d4ae48729800d52009b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2174, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84249e57debf45d9b6125a25574775a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7114, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c18ba6109349068ef53ec8d66b7ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8174, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099074c5b8bd4b65a12358c12c686b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8858, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792cce28c6ce47cbbd7043ec013b0be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5295, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb5ba4b3b2e4c4db0896345a25bf1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.4088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7108, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df916f3e91814d0197e0be47c90f029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5837, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096699d7346645f6aadb5f9bc12009f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedfdfff6cce49879d16534de97de4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/2295 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1584, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, data, lossfn, epochs=1, max_seq_len=512):\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for epoch in range(epochs):\n",
    "        for X in tqdm(data):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # token processing\n",
    "            tokens = tokenizer(X, padding='longest', max_length=max_seq_len, truncation=True)\n",
    "            # the original input\n",
    "            unmasked_tokens = torch.tensor(tokens.input_ids, dtype=torch.long).cuda()\n",
    "            zero_tokens = unmasked_tokens == 0\n",
    "            rand_nums = torch.rand(unmasked_tokens.shape).cuda() <= 0.15\n",
    "\n",
    "            masked_tokens = unmasked_tokens.clone()\n",
    "            masked_tokens[rand_nums] = tokenizer.mask_token_id\n",
    "            masked_tokens[zero_tokens] = 0\n",
    "\n",
    "            output, _classifications = model(masked_tokens)\n",
    "            masked_mask = masked_tokens == tokenizer.mask_token_id\n",
    "            #expected_output_at_masks = torch.masked_select(unmasked_tokens,    masked_mask)\n",
    "            expected_output_at_masks = unmasked_tokens[masked_mask]\n",
    "            unnormed_probs_at_masks = output[masked_mask]\n",
    "            loss = lossfn(unnormed_probs_at_masks, expected_output_at_masks) \n",
    "\n",
    "            \n",
    "            #print(unmasked_tokens)\n",
    "            #print(masked_tokens)\n",
    "            #print(output)\n",
    "            #print(expected_output_at_masks)\n",
    "            #print(unnormed_probs_at_masks)\n",
    "            #break\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print(loss)\n",
    "\n",
    "\n",
    "train(bert, optimizer, train_dataloader, lossfn, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 0.09), (',', 0.02), ('of', 0.02), ('to', 0.01), ('was', 0.01)]\n"
     ]
    }
   ],
   "source": [
    "def ascii_art_probs(model, sentence):\n",
    "    token_ids = torch.Tensor(tokenizer.encode(sentence)).long().unsqueeze(0)\n",
    "    mask_idxs = set()\n",
    "    for idx, token_id in enumerate(token_ids[0]):\n",
    "        if token_id == 103: # 103 == [MASK]\n",
    "            mask_idxs.add(idx)\n",
    "    unnormalized_output, _classifications = bert(token_ids.cuda())\n",
    "    output = torch.log_softmax(unnormalized_output, dim=-1)\n",
    "    top_k = torch.topk(output, 5, dim=-1)\n",
    "    results = []\n",
    "    for seq_i, seq_top_k in enumerate(top_k.indices[0]):\n",
    "        if seq_i in mask_idxs:\n",
    "            results.append(list(zip(tokenizer.convert_ids_to_tokens(seq_top_k), [round(x.item(), 2) for x in top_k.values[0][seq_i].exp()])))\n",
    "    for l in results:\n",
    "        print(l)\n",
    "\n",
    "ascii_art_probs(bert, \"The [MASK] loves to eat.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3810jvsc74a57bd0767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}