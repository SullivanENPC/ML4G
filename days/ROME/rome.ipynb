{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import transformers\n",
    "from einops import *\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "device = \"cuda:3\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 1600)\n",
      "    (wpe): Embedding(1024, 1600)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (12): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (13): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (14): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (15): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (16): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (17): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (18): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (19): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (20): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (21): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (22): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (23): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (24): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (25): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (26): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (27): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (28): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (29): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (30): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (31): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (32): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (33): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (34): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (35): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (36): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (37): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (38): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (39): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (40): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (41): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (42): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (43): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (44): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (45): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (46): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (47): GPT2Block(\n",
      "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\"gpt2-xl\")\n",
    "model.to(device)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "print(model)\n",
    "model.last_acts = []\n",
    "for layer in model.transformer.h:\n",
    "    layer.mlp.register_forward_hook(\n",
    "        lambda module, input, output: model.last_acts.append(output)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is located in the city of Paris, France. The tower is the tallest\n",
      "The Colosseum is located in the city of Rome, Italy. It is the largest Roman\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(model.generate(tokenizer(\"The Eiffel Tower is located in the city of\",return_tensors=\"pt\")[\"input_ids\"].to(device))[0]))\n",
    "print(tokenizer.decode(model.generate(tokenizer(\"The Colosseum is located in the city of\",return_tensors=\"pt\")[\"input_ids\"].to(device))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[13.5262],\n",
      "         [ 3.8200]]], device='cuda:3'), tensor([[[ 5.0347],\n",
      "         [12.6485]]], device='cuda:3')]\n",
      "out tokens [[6342], [10598]]\n",
      "tensor([[-9.7061, -9.7419, -9.6973, -9.6970, -9.6586, -9.7063, -9.7081, -9.7093,\n",
      "         -9.6939, -9.7055, -9.7067],\n",
      "        [-9.7079, -9.7242, -9.7019, -9.6821, -9.6573, -9.6949, -9.7047, -9.7562,\n",
      "         -9.7042, -9.7114, -9.7598],\n",
      "        [-9.7005, -9.7315, -9.6913, -9.6717, -9.6624, -9.6870, -9.7002, -9.7852,\n",
      "         -9.7025, -9.7109, -9.7902],\n",
      "        [-9.7045, -9.7193, -9.6804, -9.6641, -9.6325, -9.6843, -9.7039, -9.8033,\n",
      "         -9.6984, -9.7159, -9.8077],\n",
      "        [-9.7038, -9.7254, -9.6610, -9.6723, -9.6595, -9.6815, -9.7143, -9.8139,\n",
      "         -9.6995, -9.7180, -9.8215],\n",
      "        [-9.7026, -9.7171, -9.6744, -9.6871, -9.6197, -9.6780, -9.7126, -9.8241,\n",
      "         -9.6996, -9.7182, -9.8324],\n",
      "        [-9.7023, -9.7062, -9.6729, -9.6516, -9.5889, -9.6774, -9.7260, -9.8310,\n",
      "         -9.7001, -9.7177, -9.8369],\n",
      "        [-9.7047, -9.7024, -9.6896, -9.6251, -9.5911, -9.6748, -9.7247, -9.8258,\n",
      "         -9.7021, -9.7216, -9.8397],\n",
      "        [-9.7041, -9.7012, -9.6803, -9.6713, -9.5800, -9.6820, -9.7388, -9.8445,\n",
      "         -9.7053, -9.7215, -9.8643],\n",
      "        [-9.7010, -9.6962, -9.6549, -9.6355, -9.6335, -9.6750, -9.7450, -9.8662,\n",
      "         -9.7023, -9.7320, -9.8672],\n",
      "        [-9.6971, -9.6920, -9.6705, -9.5675, -9.6682, -9.6717, -9.7482, -9.8866,\n",
      "         -9.7055, -9.7344, -9.8638],\n",
      "        [-9.6957, -9.6907, -9.6758, -9.5924, -9.7132, -9.6726, -9.7496, -9.8974,\n",
      "         -9.7051, -9.7338, -9.8397],\n",
      "        [-9.6952, -9.6896, -9.6960, -9.6259, -9.7291, -9.6759, -9.7394, -9.9093,\n",
      "         -9.7080, -9.7257, -9.8241],\n",
      "        [-9.6913, -9.6919, -9.6676, -9.5945, -9.7493, -9.6743, -9.7283, -9.9112,\n",
      "         -9.7061, -9.7170, -9.8082],\n",
      "        [-9.6915, -9.6930, -9.6803, -9.6355, -9.6095, -9.6772, -9.7198, -9.9134,\n",
      "         -9.7069, -9.7137, -9.7954],\n",
      "        [-9.6909, -9.6939, -9.6835, -9.6058, -9.6911, -9.6784, -9.7241, -9.9024,\n",
      "         -9.7044, -9.7132, -9.7812],\n",
      "        [-9.6904, -9.6884, -9.6861, -9.6289, -9.6588, -9.6716, -9.7189, -9.9064,\n",
      "         -9.7018, -9.7149, -9.7821],\n",
      "        [-9.6883, -9.6888, -9.6828, -9.5838, -9.6904, -9.6772, -9.7287, -9.9293,\n",
      "         -9.7003, -9.7136, -9.8396],\n",
      "        [-9.6903, -9.6973, -9.6919, -9.6853, -9.6934, -9.6807, -9.7189, -9.9559,\n",
      "         -9.7078, -9.7135, -9.8656],\n",
      "        [-9.6920, -9.6899, -9.6944, -9.5693, -9.7093, -9.6854, -9.6832, -9.8727,\n",
      "         -9.7020, -9.7113, -9.8697],\n",
      "        [-9.6947, -9.6904, -9.6903, -9.5622, -9.7088, -9.6933, -9.6985, -9.8342,\n",
      "         -9.7017, -9.7116, -9.8504],\n",
      "        [-9.6979, -9.6871, -9.6928, -9.5874, -9.6950, -9.6935, -9.7110, -9.8397,\n",
      "         -9.7021, -9.7245, -9.7938],\n",
      "        [-9.6981, -9.6859, -9.6833, -9.6294, -9.6976, -9.6985, -9.7032, -9.8333,\n",
      "         -9.7035, -9.7157, -9.7614],\n",
      "        [-9.6991, -9.6896, -9.6848, -9.6396, -9.7041, -9.6977, -9.7107, -9.8196,\n",
      "         -9.7028, -9.7081, -9.7423],\n",
      "        [-9.7018, -9.6862, -9.6823, -9.6998, -9.7010, -9.7010, -9.7015, -9.8082,\n",
      "         -9.6981, -9.7081, -9.6792],\n",
      "        [-9.7011, -9.6926, -9.6891, -9.6468, -9.7054, -9.7003, -9.7028, -9.7727,\n",
      "         -9.6944, -9.7076, -9.6390],\n",
      "        [-9.7013, -9.6934, -9.6809, -9.6499, -9.7064, -9.7020, -9.6996, -9.7510,\n",
      "         -9.6945, -9.6998, -9.5700],\n",
      "        [-9.7010, -9.6917, -9.6874, -9.6537, -9.7030, -9.7026, -9.6990, -9.7402,\n",
      "         -9.6962, -9.7014, -9.5724],\n",
      "        [-9.7030, -9.6944, -9.6756, -9.6940, -9.7046, -9.7017, -9.7010, -9.7313,\n",
      "         -9.6952, -9.7012, -9.5280],\n",
      "        [-9.7019, -9.6935, -9.6833, -9.6939, -9.7028, -9.7059, -9.7022, -9.7168,\n",
      "         -9.6973, -9.7036, -9.4685],\n",
      "        [-9.7035, -9.6955, -9.6902, -9.6943, -9.7008, -9.7048, -9.7028, -9.6924,\n",
      "         -9.6937, -9.7062, -9.4043],\n",
      "        [-9.7015, -9.6921, -9.6895, -9.6811, -9.6949, -9.7059, -9.7066, -9.6934,\n",
      "         -9.6970, -9.7052, -9.3603],\n",
      "        [-9.7008, -9.6928, -9.6914, -9.6714, -9.7031, -9.7072, -9.7066, -9.6872,\n",
      "         -9.6998, -9.7020, -9.3976],\n",
      "        [-9.7026, -9.6949, -9.6856, -9.7001, -9.7015, -9.7050, -9.7065, -9.6889,\n",
      "         -9.6962, -9.7027, -9.3880],\n",
      "        [-9.7007, -9.6951, -9.6886, -9.6757, -9.6955, -9.7041, -9.7058, -9.6898,\n",
      "         -9.6953, -9.7016, -9.3357],\n",
      "        [-9.7004, -9.6948, -9.6888, -9.6777, -9.6889, -9.7033, -9.7033, -9.6916,\n",
      "         -9.6932, -9.7010, -9.3047],\n",
      "        [-9.6994, -9.6977, -9.7003, -9.6893, -9.6948, -9.7025, -9.7039, -9.6982,\n",
      "         -9.6956, -9.7008, -9.3190],\n",
      "        [-9.6984, -9.6971, -9.6965, -9.6953, -9.6930, -9.7034, -9.7027, -9.6922,\n",
      "         -9.6999, -9.7000, -9.2850],\n",
      "        [-9.6980, -9.6956, -9.6968, -9.6957, -9.7055, -9.7047, -9.7037, -9.6876,\n",
      "         -9.6982, -9.7002, -9.3475],\n",
      "        [-9.6972, -9.6985, -9.6967, -9.6986, -9.7008, -9.7013, -9.6999, -9.6835,\n",
      "         -9.6941, -9.7016, -9.2136],\n",
      "        [-9.6949, -9.6925, -9.6979, -9.6941, -9.6999, -9.7053, -9.6998, -9.6965,\n",
      "         -9.6930, -9.7017, -9.1265],\n",
      "        [-9.6951, -9.6950, -9.6927, -9.7014, -9.7018, -9.7022, -9.7001, -9.7000,\n",
      "         -9.6970, -9.7021, -9.3217],\n",
      "        [-9.6960, -9.6975, -9.7003, -9.7030, -9.7034, -9.7028, -9.7010, -9.6880,\n",
      "         -9.7003, -9.7033, -9.2180],\n",
      "        [-9.6945, -9.6962, -9.7011, -9.7024, -9.7024, -9.7019, -9.7017, -9.7010,\n",
      "         -9.7073, -9.7037, -9.3562],\n",
      "        [-9.6917, -9.6995, -9.7060, -9.7023, -9.7043, -9.7022, -9.7027, -9.7016,\n",
      "         -9.7018, -9.7011, -9.3474],\n",
      "        [-9.6945, -9.7000, -9.7034, -9.7020, -9.7038, -9.7030, -9.7036, -9.7039,\n",
      "         -9.7049, -9.7042, -9.4016],\n",
      "        [-9.7116, -9.7021, -9.7041, -9.7024, -9.7026, -9.7020, -9.7026, -9.7038,\n",
      "         -9.7016, -9.7042, -9.5600],\n",
      "        [-9.7038, -9.7038, -9.7038, -9.7038, -9.7038, -9.7038, -9.7038, -9.7038,\n",
      "         -9.7038, -9.7038, -9.7277]])\n",
      "diffs shape torch.Size([48, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbfb88224f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_switched_activations(model, main_text, alternatives):\n",
    "    main_tokens = tokenizer(main_text)[\"input_ids\"]\n",
    "    alternatives_tokens = [\n",
    "        (tokenizer(x[0])[\"input_ids\"], tokenizer(x[1])[\"input_ids\"])\n",
    "        for x in alternatives\n",
    "    ]\n",
    "    assert all([len(x[1]) == 1 for x in alternatives_tokens])\n",
    "    alternative_inputs = [t.tensor(x[0]+main_tokens) for x in alternatives_tokens]\n",
    "    alternative_activations = []\n",
    "    logits_in_question = []\n",
    "    for ipt,a_t in zip(alternative_inputs,alternatives_tokens):\n",
    "        with t.no_grad():\n",
    "            logits = model(ipt.unsqueeze(0).to(device)).logits\n",
    "        logits_in_question.append(logits[:,-1,[at[1] for at in alternatives_tokens]])\n",
    "        alternative_activations.append(model.last_acts)\n",
    "        model.last_acts=[]\n",
    "    return alternative_activations, logits_in_question, alternative_inputs, [x[1] for x in alternatives_tokens]\n",
    "    \n",
    "def evaluate_switched_mlp_activations(model, main_text,alternatives,frac=0.1):\n",
    "    acts, logits_in_question,inputs,out_tokens = get_switched_activations(model, main_text, alternatives)\n",
    "    print(\"out tokens\", out_tokens)\n",
    "    n_layers, n_tokens = len(acts[0]), acts[0][0].shape[1]\n",
    "    # batching this ugh\n",
    "    diffs= []\n",
    "    for layer_idx in range(n_layers):\n",
    "        def hook(module,input,output_t):\n",
    "            output=output_t[0]\n",
    "            output = output+0\n",
    "            for token_idx in range(n_tokens):\n",
    "                output[token_idx,token_idx] =output[0,token_idx]*(1-frac)+frac*acts[1][layer_idx][0,token_idx]\n",
    "            return (output,)+output_t[1:]\n",
    "        try:\n",
    "            hook_handle = model.transformer.h[layer_idx].register_forward_hook(hook)\n",
    "            input_batch = repeat(inputs[0], \"a -> z a\",z=n_tokens)\n",
    "            with t.no_grad():\n",
    "                l_i_q = model(input_batch.to(device)).logits[:, -1, out_tokens]\n",
    "            diff = l_i_q[:,1]-l_i_q[:,0]\n",
    "        finally:\n",
    "            hook_handle.remove()\n",
    "        diffs.append(diff)\n",
    "    diffs = t.stack(diffs).squeeze(-1).cpu()\n",
    "    print(diffs)\n",
    "    print(\"diffs shape\", diffs.shape)\n",
    "    return plt.imshow(diffs)\n",
    "    return diffs\n",
    "examples = [[\" is located in the city of\", [[\"The Eiffel Tower\",\" Paris\"], [\"The Colosseum\", \" Rome\"]]],\n",
    "[\" is a major attraction of the city of\", [[\"The Eiffel Tower\",\" Paris\"], [\"The Colosseum\", \" Rome\"]]]]\n",
    "a, l,i,it = get_switched_activations(model, *examples[0])\n",
    "print(l)\n",
    "evaluate_switched_mlp_activations(model,*examples[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
